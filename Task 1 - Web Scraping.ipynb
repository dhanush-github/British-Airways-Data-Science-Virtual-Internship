{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "---\n",
    "\n",
    "## Web scraping and analysis\n",
    "\n",
    "This Jupyter notebook includes some code to get you started with web scraping. We will use a package called `BeautifulSoup` to collect the data from the web. Once you've collected your data and saved it into a local `.csv` file you should start with your analysis.\n",
    "\n",
    "### Scraping data from Skytrax\n",
    "\n",
    "If you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n",
    "\n",
    "If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use `Python` and `BeautifulSoup` to collect all the links to the reviews and then to collect the text data on each of the individual review links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an empty list to collect all reviews\n",
    "reviews = []\n",
    "\n",
    "#create an empty list to collect all ratings (rated on a scale out of 10)\n",
    "ratings = []\n",
    "\n",
    "#creating an empty list to collect date\n",
    "date = []\n",
    "\n",
    "#creating an empty list to collect reviewer's country\n",
    "country = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 total reviews\n",
      "Scraping page 2\n",
      "   ---> 200 total reviews\n",
      "Scraping page 3\n",
      "   ---> 300 total reviews\n",
      "Scraping page 4\n",
      "   ---> 400 total reviews\n",
      "Scraping page 5\n",
      "   ---> 500 total reviews\n",
      "Scraping page 6\n",
      "   ---> 600 total reviews\n",
      "Scraping page 7\n",
      "   ---> 700 total reviews\n",
      "Scraping page 8\n",
      "   ---> 800 total reviews\n",
      "Scraping page 9\n",
      "   ---> 900 total reviews\n",
      "Scraping page 10\n",
      "   ---> 1000 total reviews\n",
      "Scraping page 11\n",
      "   ---> 1100 total reviews\n",
      "Scraping page 12\n",
      "   ---> 1200 total reviews\n",
      "Scraping page 13\n",
      "   ---> 1300 total reviews\n",
      "Scraping page 14\n",
      "   ---> 1400 total reviews\n",
      "Scraping page 15\n",
      "   ---> 1500 total reviews\n",
      "Scraping page 16\n",
      "   ---> 1600 total reviews\n",
      "Scraping page 17\n",
      "   ---> 1700 total reviews\n",
      "Scraping page 18\n",
      "   ---> 1800 total reviews\n",
      "Scraping page 19\n",
      "   ---> 1900 total reviews\n",
      "Scraping page 20\n",
      "   ---> 2000 total reviews\n",
      "Scraping page 21\n",
      "   ---> 2100 total reviews\n",
      "Scraping page 22\n",
      "   ---> 2200 total reviews\n",
      "Scraping page 23\n",
      "   ---> 2300 total reviews\n",
      "Scraping page 24\n",
      "   ---> 2400 total reviews\n",
      "Scraping page 25\n",
      "   ---> 2500 total reviews\n",
      "Scraping page 26\n",
      "   ---> 2600 total reviews\n",
      "Scraping page 27\n",
      "   ---> 2700 total reviews\n",
      "Scraping page 28\n",
      "   ---> 2800 total reviews\n",
      "Scraping page 29\n",
      "   ---> 2900 total reviews\n",
      "Scraping page 30\n",
      "   ---> 3000 total reviews\n",
      "Scraping page 31\n",
      "   ---> 3100 total reviews\n",
      "Scraping page 32\n",
      "Error on page 32\n",
      "   ---> 3200 total reviews\n",
      "Scraping page 33\n",
      "Error on page 33\n",
      "   ---> 3300 total reviews\n",
      "Scraping page 34\n",
      "Error on page 34\n",
      "   ---> 3400 total reviews\n",
      "Scraping page 35\n",
      "   ---> 3500 total reviews\n",
      "Scraping page 36\n",
      "Error on page 36\n",
      "Error on page 36\n",
      "   ---> 3600 total reviews\n",
      "Scraping page 37\n",
      "   ---> 3700 total reviews\n",
      "Scraping page 38\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 39\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 40\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 41\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 42\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 43\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 44\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 45\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 46\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 47\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 48\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 49\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 50\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 51\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 52\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 53\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 54\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 55\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 56\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 57\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 58\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 59\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 60\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 61\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 62\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 63\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 64\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 65\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 66\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 67\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 68\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 69\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 70\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 71\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 72\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 73\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 74\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 75\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 76\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 77\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 78\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 79\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 80\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 81\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 82\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 83\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 84\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 85\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 86\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 87\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 88\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 89\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 90\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 91\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 92\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 93\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 94\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 95\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 96\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 97\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 98\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 99\n",
      "   ---> 3742 total reviews\n",
      "Scraping page 100\n",
      "   ---> 3742 total reviews\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 100\n",
    "page_size = 100\n",
    "\n",
    "\n",
    "\n",
    "# Looping through pages from 1 to 100\n",
    "for i in range(1, pages + 1):\n",
    "    \n",
    "    page = requests.get(f\"https://www.airlinequality.com/airline-reviews/british-airways/page/{i}/?sortby=post_date%3ADesc&pagesize=100\")\n",
    "\n",
    "    soup = BeautifulSoup(page.content,\"html5\")\n",
    "\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        reviews.append(para.get_text())\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    #to extract ratings\n",
    "    for item in soup.find_all(\"div\",class_ = \"rating-10\"):\n",
    "        try: \n",
    "            ratings.append(item.span.text)\n",
    "        except:\n",
    "            print(f\"Error on page {i}\")\n",
    "            ratings.append(\"None\")\n",
    "            \n",
    "    #extract date\n",
    "    for item in soup.find_all(\"time\"):\n",
    "        date.append(item.text)\n",
    "        \n",
    "    #extracting country names of reviewer's\n",
    "    for item in soup.find_all(\"h3\"):\n",
    "        country.append(item.span.next_sibling.text.strip(\" ()\"))\n",
    "    \n",
    "    print(f\"   ---> {len(reviews)} total reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3742\n",
      "3842\n",
      "3742\n",
      "3742\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews))\n",
    "print(len(ratings))\n",
    "print(len(date))\n",
    "print(len(country))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅ Trip Verified |  I have come to boarding and...</td>\n",
       "      <td>28th January 2024</td>\n",
       "      <td>Ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified | Stinking nappies being chang...</td>\n",
       "      <td>26th January 2024</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified | Worst service ever. Lost bag...</td>\n",
       "      <td>23rd January 2024</td>\n",
       "      <td>Germany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>✅ Trip Verified |  BA 246 21JAN 2023 Did not a...</td>\n",
       "      <td>21st January 2024</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified | Not a great experience. I co...</td>\n",
       "      <td>18th January 2024</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews               date  \\\n",
       "0  ✅ Trip Verified |  I have come to boarding and...  28th January 2024   \n",
       "1  ✅ Trip Verified | Stinking nappies being chang...  26th January 2024   \n",
       "2  ✅ Trip Verified | Worst service ever. Lost bag...  23rd January 2024   \n",
       "3  ✅ Trip Verified |  BA 246 21JAN 2023 Did not a...  21st January 2024   \n",
       "4  ✅ Trip Verified | Not a great experience. I co...  18th January 2024   \n",
       "\n",
       "          country  \n",
       "0         Ukraine  \n",
       "1  United Kingdom  \n",
       "2         Germany  \n",
       "3  United Kingdom  \n",
       "4  United Kingdom  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"reviews\":reviews,\"date\":date,\"country\":country})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3737</th>\n",
       "      <td>Flew LHR - VIE return operated by bmi but BA a...</td>\n",
       "      <td>29th August 2012</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>LHR to HAM. Purser addresses all club passenge...</td>\n",
       "      <td>28th August 2012</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>My son who had worked for British Airways urge...</td>\n",
       "      <td>12th October 2011</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3740</th>\n",
       "      <td>London City-New York JFK via Shannon on A318 b...</td>\n",
       "      <td>11th October 2011</td>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3741</th>\n",
       "      <td>SIN-LHR BA12 B747-436 First Class. Old aircraf...</td>\n",
       "      <td>9th October 2011</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reviews               date  \\\n",
       "3737  Flew LHR - VIE return operated by bmi but BA a...   29th August 2012   \n",
       "3738  LHR to HAM. Purser addresses all club passenge...   28th August 2012   \n",
       "3739  My son who had worked for British Airways urge...  12th October 2011   \n",
       "3740  London City-New York JFK via Shannon on A318 b...  11th October 2011   \n",
       "3741  SIN-LHR BA12 B747-436 First Class. Old aircraf...   9th October 2011   \n",
       "\n",
       "             country  \n",
       "3737  United Kingdom  \n",
       "3738  United Kingdom  \n",
       "3739  United Kingdom  \n",
       "3740   United States  \n",
       "3741  United Kingdom  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ratings'] = ratings[1:3743]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       3\n",
       "1       2\n",
       "2       1\n",
       "3       6\n",
       "4       3\n",
       "       ..\n",
       "3737    8\n",
       "3738    2\n",
       "3739    7\n",
       "3740    1\n",
       "3741    9\n",
       "Name: ratings, Length: 3742, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ratings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅ Trip Verified |  I have come to boarding and...</td>\n",
       "      <td>28th January 2024</td>\n",
       "      <td>Ukraine</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified | Stinking nappies being chang...</td>\n",
       "      <td>26th January 2024</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified | Worst service ever. Lost bag...</td>\n",
       "      <td>23rd January 2024</td>\n",
       "      <td>Germany</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>✅ Trip Verified |  BA 246 21JAN 2023 Did not a...</td>\n",
       "      <td>21st January 2024</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified | Not a great experience. I co...</td>\n",
       "      <td>18th January 2024</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3737</th>\n",
       "      <td>Flew LHR - VIE return operated by bmi but BA a...</td>\n",
       "      <td>29th August 2012</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3738</th>\n",
       "      <td>LHR to HAM. Purser addresses all club passenge...</td>\n",
       "      <td>28th August 2012</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3739</th>\n",
       "      <td>My son who had worked for British Airways urge...</td>\n",
       "      <td>12th October 2011</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3740</th>\n",
       "      <td>London City-New York JFK via Shannon on A318 b...</td>\n",
       "      <td>11th October 2011</td>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3741</th>\n",
       "      <td>SIN-LHR BA12 B747-436 First Class. Old aircraf...</td>\n",
       "      <td>9th October 2011</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3742 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reviews               date  \\\n",
       "0     ✅ Trip Verified |  I have come to boarding and...  28th January 2024   \n",
       "1     ✅ Trip Verified | Stinking nappies being chang...  26th January 2024   \n",
       "2     ✅ Trip Verified | Worst service ever. Lost bag...  23rd January 2024   \n",
       "3     ✅ Trip Verified |  BA 246 21JAN 2023 Did not a...  21st January 2024   \n",
       "4     ✅ Trip Verified | Not a great experience. I co...  18th January 2024   \n",
       "...                                                 ...                ...   \n",
       "3737  Flew LHR - VIE return operated by bmi but BA a...   29th August 2012   \n",
       "3738  LHR to HAM. Purser addresses all club passenge...   28th August 2012   \n",
       "3739  My son who had worked for British Airways urge...  12th October 2011   \n",
       "3740  London City-New York JFK via Shannon on A318 b...  11th October 2011   \n",
       "3741  SIN-LHR BA12 B747-436 First Class. Old aircraf...   9th October 2011   \n",
       "\n",
       "             country ratings  \n",
       "0            Ukraine       3  \n",
       "1     United Kingdom       2  \n",
       "2            Germany       1  \n",
       "3     United Kingdom       6  \n",
       "4     United Kingdom       3  \n",
       "...              ...     ...  \n",
       "3737  United Kingdom       8  \n",
       "3738  United Kingdom       2  \n",
       "3739  United Kingdom       7  \n",
       "3740   United States       1  \n",
       "3741  United Kingdom       9  \n",
       "\n",
       "[3742 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"BA_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now you have your dataset for this task! The loops above collected 1000 reviews by iterating through the paginated pages on the website. However, if you want to collect more data, try increasing the number of pages!\n",
    "\n",
    " The next thing that you should do is clean this data to remove any unnecessary text from each of the rows. For example, \"✅ Trip Verified\" can be removed from each row if it exists, as it's not relevant to what we want to investigate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f7924c4c56b083e0e50eadfe7ef592a7a8ef70df33a0047f82280e6be1afe15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
